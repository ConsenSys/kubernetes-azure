#cloud-config

write_files:
  - path: "/etc/kubernetes/ssl/ca.pem"
    permissions: "0644"
    owner: "root"
    encoding: "base64"
    content: |
        ${MASTER_CA_PEM_CONTENTS_BASE64}

  - path: "/etc/kubernetes/ssl/apiserver.pem"
    permissions: "0644"
    owner: "root"
    encoding: "base64"
    content: |
        ${MASTER_APISERVER_PEM_CONTENTS_BASE64}

  - path: "/etc/kubernetes/ssl/apiserver-key.pem"
    permissions: "0600"
    owner: "root"
    encoding: "base64"
    content: |
        ${MASTER_APISERVER_KEY_PEM_CONTENTS_BASE64}

  - path: "/opt/bin/download-k8s-binary"
    permissions: "0755"
    content: |
      #!/bin/bash

      K8S_VERSION=v1.2.0

      mkdir -p /opt/bin

      FILE=$1
      if [ ! -f /opt/bin/$FILE ]; then
        curl -sSL -o /opt/bin/$FILE https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/$FILE
        chmod +x /opt/bin/$FILE
      else
        # We check the version of the binary
        INSTALLED_VERSION=$(/opt/bin/$FILE --version)
        MATCH=$(echo "${INSTALLED_VERSION}" | grep -c "${K8S_VERSION}")
        if [ $MATCH -eq 0 ]; then
          # The version is different
          curl -sSL -o /opt/bin/$FILE https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/$FILE
          chmod +x /opt/bin/$FILE
        fi
      fi
  - path: "/etc/kubernetes/manifests/kube-apiserver.yaml"
    permissions: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-apiserver
          image: gcr.io/google_containers/hyperkube:v1.2.0
          command:
          - /hyperkube
          - apiserver
          - --bind-address=0.0.0.0
          - --etcd-servers=http://${IFR_NETWORK_ETCD_PRIV_IP_00}:2379
          - --allow-privileged=true
          - --service-cluster-ip-range=${IFR_NETWORK_SERVICES_CIDR}
          - --secure-port=443
          - --advertise-address=$private_ipv4
          - --admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota
          - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem
          - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          ports:
          - containerPort: 443
            hostPort: 443
            name: https
          - containerPort: 8080
            hostPort: 8080
            name: local
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host

  - path: "/etc/kubernetes/manifests/kube-proxy.yaml"
    permissions: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-proxy
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-proxy
          image: gcr.io/google_containers/hyperkube:v1.2.0
          command:
          - /hyperkube
          - proxy
          - --master=http://127.0.0.1:8080
          - --proxy-mode=iptables
          securityContext:
            privileged: true
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host

  - path: "/etc/kubernetes/manifests/kube-podmaster.yaml"
    permissions: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-podmaster
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: scheduler-elector
          image: gcr.io/google_containers/podmaster:1.1
          command:
          - /podmaster
          - --etcd-servers=http://${IFR_NETWORK_ETCD_PRIV_IP_00}:2379
          - --key=scheduler
          - --whoami=$private_ipv4
          - --source-file=/src/manifests/kube-scheduler.yaml
          - --dest-file=/dst/manifests/kube-scheduler.yaml
          volumeMounts:
          - mountPath: /src/manifests
            name: manifest-src
            readOnly: true
          - mountPath: /dst/manifests
            name: manifest-dst
        - name: controller-manager-elector
          image: gcr.io/google_containers/podmaster:1.1
          command:
          - /podmaster
          - --etcd-servers=http://${IFR_NETWORK_ETCD_PRIV_IP_00}:2379
          - --key=controller
          - --whoami=$private_ipv4
          - --source-file=/src/manifests/kube-controller-manager.yaml
          - --dest-file=/dst/manifests/kube-controller-manager.yaml
          terminationMessagePath: /dev/termination-log
          volumeMounts:
          - mountPath: /src/manifests
            name: manifest-src
            readOnly: true
          - mountPath: /dst/manifests
            name: manifest-dst
        volumes:
        - hostPath:
            path: /srv/kubernetes/manifests
          name: manifest-src
        - hostPath:
            path: /etc/kubernetes/manifests
          name: manifest-dst

  - path: "/srv/kubernetes/manifests/kube-controller-manager.yaml"
    permissions: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-controller-manager
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-controller-manager
          image: gcr.io/google_containers/hyperkube:v1.2.0
          command:
          - /hyperkube
          - controller-manager
          - --master=http://127.0.0.1:8080
          - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --root-ca-file=/etc/kubernetes/ssl/ca.pem
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10252
            initialDelaySeconds: 15
            timeoutSeconds: 1
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host

  - path: "/srv/kubernetes/manifests/kube-scheduler.yaml"
    permissions: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-scheduler
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-scheduler
          image: gcr.io/google_containers/hyperkube:v1.2.0
          command:
          - /hyperkube
          - scheduler
          - --master=http://127.0.0.1:8080
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10251
            initialDelaySeconds: 15
            timeoutSeconds: 1

coreos:
  flannel:
    iface: $private_ipv4
    etcd_endpoints: http://${IFR_NETWORK_ETCD_PRIV_IP_00}:2379
  units:
    - name: flanneld.service
      content: |
        [Unit]
        Description=Network fabric for containers
        Documentation=https://github.com/coreos/flannel
        Requires=early-docker.service
        After=etcd.service etcd2.service early-docker.service
        Before=early-docker.target

        [Service]
        Type=notify
        Restart=always
        RestartSec=5
        Environment="TMPDIR=/var/tmp/"
        Environment="DOCKER_HOST=unix:///var/run/early-docker.sock"
        Environment="FLANNEL_VER=0.5.5"
        Environment="ETCD_SSL_DIR=/etc/ssl/etcd"
        Environment="FLANNEL_ENV_FILE=/run/flannel/options.env"
        LimitNOFILE=40000
        LimitNPROC=1048576
        ExecStartPre=/sbin/modprobe ip_tables
        ExecStartPre=/usr/bin/mkdir -p /run/flannel
        ExecStartPre=/usr/bin/mkdir -p ${ETCD_SSL_DIR}
        ExecStartPre=-/usr/bin/touch ${FLANNEL_ENV_FILE}

        ExecStart=/usr/libexec/sdnotify-proxy /run/flannel/sd.sock \
          /usr/bin/docker run --net=host --privileged=true --rm \
          --volume=/run/flannel:/run/flannel \
          --env=NOTIFY_SOCKET=/run/flannel/sd.sock \
          --env-file=${FLANNEL_ENV_FILE} \
          --volume=/usr/share/ca-certificates:/etc/ssl/certs:ro \
          --volume=${ETCD_SSL_DIR}:/etc/ssl/etcd:ro \
          quay.io/coreos/flannel:${FLANNEL_VER} /opt/bin/flanneld --ip-masq=true

        # Update docker options
        ExecStartPost=/usr/bin/docker run --net=host --rm -v /run:/run \
          quay.io/coreos/flannel:${FLANNEL_VER} \
          /opt/bin/mk-docker-opts.sh -d /run/flannel_docker_opts.env -i
      drop-ins:
        - name: "50-ExecStartPre-flannel-network.conf"
          content: |
            [Service]
            ExecStartPre=/usr/bin/curl -X PUT -d "value={\"Network\":\"${IFR_NETWORK_PODS_CIDR}\",\"Backend\":{\"Type\":\"vxlan\"}}" http://${IFR_NETWORK_ETCD_PRIV_IP_00}:2379/v2/keys/coreos.com/network/config
    - name: docker.service
      drop-ins:
        - name: "40-flannel.conf"
          content: |
            [Unit]
            Requires=flanneld.service
            After=flanneld.service

            [Service]
            Restart=always
            Restart=on-failure
    - name: kubelet.service
      enable: true
      command: start
      content: |
        # /usr/lib64/systemd/system/kubelet.service
        [Unit]
        Description=Kubernetes Kubelet

        [Service]
        ExecStartPre=/bin/bash -c "/opt/bin/download-k8s-binary kubelet"
        ExecStart=/opt/bin/kubelet \
         --api-servers=http://127.0.0.1:8080 \
         --allow-privileged=true \
         --cadvisor-port=0 \
         --config=/etc/kubernetes/manifests \
         --cluster-dns=${IFR_NETWORK_DNS_SERVICE_IP} \
         --cluster_domain=cluster.local
        Restart=on-failure
        RestartSec=5

        [Install]
        WantedBy=multi-user.target
